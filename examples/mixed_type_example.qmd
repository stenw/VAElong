---
title: "Mixed-Type Longitudinal VAE"
subtitle: "Continuous, Binary, and Bounded Variables with Baseline Covariates"
format:
  html:
    code-fold: false
    toc: true
jupyter: vaelong
---

## Overview

This document demonstrates the full workflow of a Variational Autoencoder (VAE)
for **mixed-type longitudinal data**. The model supports:

- **Continuous** variables (e.g., biomarker measurements) — Gaussian NLL with learned variance
- **Binary** variables (e.g., symptom present/absent) — BCE loss with sigmoid
- **Bounded** variables (e.g., blood pressure in [60, 200]) — BCE loss with affine normalisation to [0,1]
- **Baseline covariates** per subject — concatenated into the encoder and decoder (CVAE)
- **Missing data** — EM-like imputation during training
- **Landmark prediction** — predict future trajectory from partial observations

::: {.callout-note}
This notebook uses the `vaelong` Jupyter kernel. To set it up, see the
instructions in **Environment setup** below, or run `make setup` from the
repository root.
:::

```{python}
import warnings

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
from torch.utils.data import DataLoader

from vaelong import (
    VariableConfig, VariableSpec,
    LongitudinalVAE,
    VAETrainer, LongitudinalDataset,
    generate_mixed_longitudinal_data, create_missing_mask,
)

torch.manual_seed(42)
np.random.seed(42)
```

## 1. Define variable types

Each feature in the time series is declared with a type. The `VariableConfig`
object drives type-aware normalisation, loss computation, and output activations.

```{python}
var_config = VariableConfig(variables=[
    VariableSpec(name='biomarker',        var_type='continuous'),
    VariableSpec(name='blood_pressure',   var_type='bounded', lower=60.0, upper=200.0),
    VariableSpec(name='symptom_present',  var_type='binary'),
    VariableSpec(name='score',            var_type='continuous'),
])

print(f"Features:   {var_config.n_features}")
print(f"Continuous: {var_config.continuous_indices}")
print(f"Binary:     {var_config.binary_indices}")
print(f"Bounded:    {var_config.bounded_indices}")
```

## 2. Generate synthetic data

We generate 500 subjects, each observed at 50 time points, with 3 additional
time-invariant baseline covariates. A large **random intercept** (`random_intercept_sd=2.0`)
ensures clear between-subject differences — some individuals will have persistently
higher or lower values, making it easier to see whether the model captures
individual-level variation.

```{python}
n_samples  = 500
seq_len    = 50
n_baseline = 3

data, baseline = generate_mixed_longitudinal_data(
    n_samples=n_samples,
    seq_len=seq_len,
    var_config=var_config,
    n_baseline_features=n_baseline,
    noise_level=0.2,
    random_intercept_sd=2.0,
    seed=42,
)

print(f"Data shape:     {data.shape}")
print(f"Baseline shape: {baseline.shape}")
print(f"Bounded var range: [{data[:, :, 1].min():.1f}, {data[:, :, 1].max():.1f}]")
print(f"Binary var unique: {np.unique(data[:, :, 2])}")
```

## 3. Introduce missing data

Longitudinal studies routinely suffer from missing observations — subjects may
miss clinic visits, sensors may fail, or lab results may be unavailable. The
model handles this through two complementary mechanisms:

1. **Binary mask.** A tensor of the same shape as the data indicates which
   values are observed (`1`) and which are missing (`0`). During training the
   reconstruction loss is computed only over observed entries, so missing values
   never contribute to the gradient.

2. **EM-like imputation** (optional, enabled with `use_em_imputation=True`).
   Within each training batch the model alternates between:
   - **E-step** — run the current model forward to predict the missing entries,
     using type-aware post-processing (round binary predictions to 0/1, clamp
     bounded predictions to [0, 1]);
   - **M-step** — fill in the missing positions with these predictions and
     update the model parameters on the completed data.

   This iterative fill-and-fit procedure lets the model learn from the full
   sequence structure even when parts of it are unobserved.

`create_missing_mask` supports three missingness patterns:

| Pattern    | Description |
|------------|-------------|
| `random`   | Each value is independently missing with probability `missing_rate` |
| `block`    | Contiguous blocks of time points are missing per feature (simulates sensor outages) |
| `monotone` | Once a feature drops out for a subject it stays missing (simulates study dropout) |

```{python}
mask = create_missing_mask(data.shape, missing_rate=0.15, pattern='random', seed=42)
data_masked = data * mask
print(f"Missing rate: {(1 - mask.mean()) * 100:.1f}%")

dataset = LongitudinalDataset(
    data_masked, mask=mask, var_config=var_config,
    baseline_covariates=baseline, normalize=True,
)

train_size = int(0.8 * len(dataset))
val_size   = len(dataset) - train_size
train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False)
```

## 4. Train the model

We use an LSTM-based VAE with baseline conditioning (CVAE). The loss function
combines proper negative log-likelihoods for each variable type so that all
contributions are on a comparable scale:

- **Continuous:** Gaussian NLL with a learned per-variable observation variance,
  $\frac{1}{2}\bigl(\log\sigma_j^2 + (x - \hat x)^2 / \sigma_j^2\bigr)$.
  The variances $\sigma_j^2$ are free parameters optimised alongside the
  network weights, which automatically down-weights noisy features.
- **Binary:** Binary cross-entropy (Bernoulli NLL).
- **Bounded:** BCE after affine normalisation to $[0, 1]$.

Training uses **EM imputation** (`use_em_imputation=True`) — at each batch the
model first imputes missing values from its current predictions (E-step), then
updates parameters on the completed data (M-step). The mask ensures
reconstruction loss is computed only over genuinely observed entries.

**Early stopping** (`patience=20`) monitors validation loss and restores the
best model weights when performance stops improving, which prevents overfitting.

```{python}
model = LongitudinalVAE(
    input_dim=var_config.n_features,
    hidden_dim=64,
    latent_dim=16,
    n_baseline=n_baseline,
    var_config=var_config,
)

trainer = VAETrainer(model, learning_rate=1e-3, beta=0.5, var_config=var_config)

history = trainer.fit(
    train_loader, val_loader=val_loader, epochs=200, verbose=True,
    use_em_imputation=True, em_iterations=2, patience=20,
)
```

### Training curves

```{python}
#| label: fig-training
#| fig-cap: "Training and validation loss over epochs."

fig, ax = plt.subplots(figsize=(7, 4))
ax.plot(history['train_loss'], label='Train')
ax.plot(history['val_loss'],   label='Validation')
ax.set_xlabel('Epoch')
ax.set_ylabel('Loss')
ax.set_title('Training and Validation Loss')
ax.legend()
plt.tight_layout()
plt.show()
```

## 5. Landmark prediction

We observe the first half of the time series (landmark at $t = 25$) and
predict the full trajectory. Below we plot **actual vs predicted** outcomes
for 3 randomly selected individuals, one panel per variable.

```{python}
#| label: fig-landmark
#| fig-cap: "Landmark prediction for 3 random individuals. The vertical dashed line marks the landmark time; the shaded region is the predicted (unobserved) future."

landmark_t = seq_len // 2  # halfway

# Collect all validation-set indices in the original dataset
val_indices = [val_ds.indices[i] for i in range(len(val_ds))]

# Pick 3 random individuals from the validation set
rng = np.random.default_rng(123)
chosen = sorted(rng.choice(len(val_indices), size=3, replace=False))
sample_idx = [val_indices[c] for c in chosen]

x_full   = torch.stack([dataset[i][0] for i in sample_idx])
mask_full = torch.stack([dataset[i][1] for i in sample_idx])
bl_full  = torch.stack([dataset[i][3] for i in sample_idx])

# Observed portion (first half)
x_obs    = x_full[:, :landmark_t, :]
mask_obs = mask_full[:, :landmark_t, :]

# Predict full trajectory from the observed portion
predicted = model.predict_from_landmark(
    x_obs, mask_obs, total_seq_len=seq_len, baseline=bl_full,
)

# Inverse-transform both actual and predicted back to original scale
actual_orig = dataset.inverse_transform(x_full).detach().numpy()
pred_orig   = dataset.inverse_transform(predicted).detach().numpy()

# --- Plot ---
var_names  = [v.name for v in var_config.variables]
n_vars     = var_config.n_features
n_individuals = 3
time_axis  = np.arange(seq_len)

fig, axes = plt.subplots(n_individuals, n_vars, figsize=(4 * n_vars, 3.5 * n_individuals),
                         sharex=True)

for row in range(n_individuals):
    for col in range(n_vars):
        ax = axes[row, col]

        actual_vals = actual_orig[row, :, col]
        pred_vals   = pred_orig[row, :, col]

        # Plot actual trajectory
        ax.plot(time_axis, actual_vals, 'k-', linewidth=1.2, label='Actual')

        # Plot predicted trajectory (full length, highlight future part)
        ax.plot(time_axis[:landmark_t], pred_vals[:landmark_t],
                'b-', linewidth=1, alpha=0.5)
        ax.plot(time_axis[landmark_t:], pred_vals[landmark_t:],
                'r-', linewidth=1.5, label='Predicted')

        # Shade the future region
        ax.axvspan(landmark_t, seq_len - 1, alpha=0.08, color='red')
        ax.axvline(landmark_t, color='grey', linestyle='--', linewidth=0.8)

        if row == 0:
            ax.set_title(var_names[col], fontsize=11)
        if col == 0:
            ax.set_ylabel(f'Individual {row + 1}', fontsize=10)
        if row == n_individuals - 1:
            ax.set_xlabel('Time')

axes[0, -1].legend(loc='upper right', fontsize=8)
fig.suptitle(f'Landmark Prediction (observed up to t = {landmark_t})',
             fontsize=13, y=1.01)
plt.tight_layout()
plt.show()
```

## 6. Prediction evaluation

We evaluate the landmark predictions across **all** validation subjects.
For each individual we observe the first half and predict the full trajectory,
then compute MAE, RMSE, and Pearson correlation on the **future** (unobserved)
portion only.

```{python}
#| label: tbl-metrics
#| tbl-cap: "Prediction accuracy on the future (unobserved) portion of the validation set."

all_actual = []
all_predicted = []

for idx in val_ds.indices:
    xi = dataset[idx][0].unsqueeze(0)
    mi = dataset[idx][1].unsqueeze(0)
    bi = dataset[idx][3].unsqueeze(0)

    xi_obs = xi[:, :landmark_t, :]
    mi_obs = mi[:, :landmark_t, :]

    pred_i = model.predict_from_landmark(
        xi_obs, mi_obs, total_seq_len=seq_len, baseline=bi,
    )

    all_actual.append(dataset.inverse_transform(xi).detach())
    all_predicted.append(dataset.inverse_transform(pred_i).detach())

all_actual = torch.cat(all_actual, dim=0).numpy()
all_predicted = torch.cat(all_predicted, dim=0).numpy()

future_actual = all_actual[:, landmark_t:, :]
future_pred   = all_predicted[:, landmark_t:, :]

print(f"{'Variable':<20s}  {'MAE':>8s}  {'RMSE':>8s}  {'Corr':>8s}")
print("-" * 50)
for col, v in enumerate(var_config.variables):
    a = future_actual[:, :, col].ravel()
    p = future_pred[:, :, col].ravel()
    mae  = np.mean(np.abs(a - p))
    rmse = np.sqrt(np.mean((a - p) ** 2))
    corr = np.corrcoef(a, p)[0, 1] if np.std(a) > 0 else float('nan')
    print(f"{v.name:<20s}  {mae:8.4f}  {rmse:8.4f}  {corr:8.4f}")
```

## 7. Benchmark: Linear Mixed Model (LMM)

As a classical statistics baseline we fit a separate **linear mixed model** per
variable on the training subjects' observed portion (t = 0 … 24). Each model
has the form

$$
y_{it} = \beta_0 + \beta_1 t + \sum_k \beta_k x_{ik}^{\text{bl}}
         + u_{0i} + u_{1i} t + \varepsilon_{it},
$$

where $u_{0i}$ and $u_{1i}$ are subject-specific random intercept and slope.
For a **new** validation subject we estimate their random effects (BLUPs) from
the 25 observed time points and predict forward.

- For the **binary** variable this is a linear probability model; predictions
  are clipped to [0, 1] and rounded.
- For the **bounded** variable, predictions are clipped to [60, 200].

```{python}
train_indices = list(train_ds.indices)
val_indices_list = list(val_ds.indices)
n_val = len(val_indices_list)

lmm_predictions = np.zeros((n_val, seq_len, var_config.n_features))

for col, var_spec in enumerate(var_config.variables):
    print(f"  Fitting LMM for {var_spec.name}...", end=" ", flush=True)

    # Long-format training data (observed portion only)
    rows = []
    for i in train_indices:
        for t in range(landmark_t):
            if mask[i, t, col] == 1.0:
                row = {'subject': int(i), 'time': t, 'y': float(data[i, t, col])}
                for b in range(n_baseline):
                    row[f'bl_{b}'] = float(baseline[i, b])
                rows.append(row)
    df_train = pd.DataFrame(rows)

    fixed_formula = 'y ~ time + ' + ' + '.join(f'bl_{b}' for b in range(n_baseline))
    re_formula = '1 + time'

    with warnings.catch_warnings():
        warnings.simplefilter('ignore')
        md = smf.mixedlm(fixed_formula, df_train, groups=df_train['subject'],
                         re_formula=re_formula)
        mdf = md.fit(reml=True, method='lbfgs')

    beta_hat = np.array(mdf.fe_params)
    D = np.array(mdf.cov_re)
    sigma2_e = mdf.scale
    print(f"done (var_e={sigma2_e:.4f})")

    for j, subj_idx in enumerate(val_indices_list):
        obs_times, obs_y = [], []
        for t in range(landmark_t):
            if mask[subj_idx, t, col] == 1.0:
                obs_times.append(t)
                obs_y.append(data[subj_idx, t, col])

        bl_vals = [baseline[subj_idx, b] for b in range(n_baseline)]

        if len(obs_times) == 0:
            for t in range(seq_len):
                x_t = np.array([1.0, t] + bl_vals)
                lmm_predictions[j, t, col] = x_t @ beta_hat
            continue

        obs_times = np.array(obs_times, dtype=float)
        obs_y = np.array(obs_y)
        n_obs = len(obs_times)

        X_obs = np.column_stack([np.ones(n_obs), obs_times,
                                 np.tile(bl_vals, (n_obs, 1))])
        Z_obs = np.column_stack([np.ones(n_obs), obs_times])

        r = obs_y - X_obs @ beta_hat
        V = Z_obs @ D @ Z_obs.T + sigma2_e * np.eye(n_obs) + 1e-6 * np.eye(n_obs)
        u_hat = D @ Z_obs.T @ np.linalg.solve(V, r)

        for t in range(seq_len):
            x_t = np.array([1.0, t] + bl_vals)
            z_t = np.array([1.0, t])
            lmm_predictions[j, t, col] = x_t @ beta_hat + z_t @ u_hat

    if var_spec.var_type == 'binary':
        lmm_predictions[:, :, col] = np.round(
            np.clip(lmm_predictions[:, :, col], 0, 1))
    elif var_spec.var_type == 'bounded':
        lmm_predictions[:, :, col] = np.clip(
            lmm_predictions[:, :, col], var_spec.lower, var_spec.upper)
```

## 8. Benchmark: Seq2Seq LSTM

As a deep-learning baseline we train an **encoder–decoder LSTM** directly for
the prediction task. The encoder reads the observed 25 time steps; a context
vector (incorporating baseline covariates) initialises the decoder, which
autoregressively unrolls the next 25 steps. Training uses teacher forcing;
inference is fully autoregressive.

```{python}
class Seq2SeqLSTM(nn.Module):
    """Encoder-decoder LSTM for direct sequence prediction."""

    def __init__(self, input_dim, hidden_dim, n_baseline, var_config):
        super().__init__()
        self.var_config = var_config
        self.encoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.baseline_proj = nn.Linear(hidden_dim + n_baseline, hidden_dim)
        self.decoder = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc_out = nn.Linear(hidden_dim, input_dim)

    def _apply_activations(self, output):
        result = output.clone()
        for idx in self.var_config.binary_indices:
            result[:, :, idx] = torch.sigmoid(result[:, :, idx])
        for idx in self.var_config.bounded_indices:
            result[:, :, idx] = torch.sigmoid(result[:, :, idx])
        return result

    def forward(self, x_obs, mask_obs, bl, future_target=None, future_len=25):
        _, (h_enc, c_enc) = self.encoder(x_obs * mask_obs)
        if bl is not None:
            h_combined = torch.cat([h_enc.squeeze(0), bl], dim=-1)
            h_dec = self.baseline_proj(h_combined).unsqueeze(0)
        else:
            h_dec = h_enc
        c_dec = c_enc

        predictions = []
        dec_input = x_obs[:, -1:, :]
        for t in range(future_len):
            dec_out, (h_dec, c_dec) = self.decoder(dec_input, (h_dec, c_dec))
            pred_t = self.fc_out(dec_out)
            pred_t = self._apply_activations(pred_t)
            predictions.append(pred_t)
            if future_target is not None and self.training:
                dec_input = future_target[:, t:t + 1, :]
            else:
                dec_input = pred_t.detach()
        return torch.cat(predictions, dim=1)


future_len = seq_len - landmark_t
train_x_obs, train_mask_obs, train_future = [], [], []
train_future_mask, train_bl = [], []

for idx in train_indices:
    xi, mi, _, bi = dataset[idx]
    train_x_obs.append(xi[:landmark_t])
    train_mask_obs.append(mi[:landmark_t])
    train_future.append(xi[landmark_t:])
    train_future_mask.append(mi[landmark_t:])
    train_bl.append(bi)

train_x_obs = torch.stack(train_x_obs)
train_mask_obs = torch.stack(train_mask_obs)
train_future = torch.stack(train_future)
train_future_mask = torch.stack(train_future_mask)
train_bl = torch.stack(train_bl)

seq2seq = Seq2SeqLSTM(var_config.n_features, 64, n_baseline, var_config)
opt_s2s = torch.optim.Adam(seq2seq.parameters(), lr=1e-3)

for epoch in range(200):
    seq2seq.train()
    perm = torch.randperm(len(train_x_obs))
    epoch_loss, n_batches = 0.0, 0

    for start in range(0, len(train_x_obs), 32):
        batch_idx = perm[start:start + 32]
        bx = train_x_obs[batch_idx]
        bm = train_mask_obs[batch_idx]
        bf = train_future[batch_idx]
        bfm = train_future_mask[batch_idx]
        bb = train_bl[batch_idx]

        pred = seq2seq(bx, bm, bb, future_target=bf, future_len=future_len)

        loss = torch.tensor(0.0)
        for cidx in var_config.continuous_indices:
            diff2 = (pred[:, :, cidx] - bf[:, :, cidx]) ** 2
            m = bfm[:, :, cidx]
            n_obs_m = m.sum()
            if n_obs_m > 0:
                loss = loss + (diff2 * m).sum() / n_obs_m

        for cidx in var_config.binary_indices + var_config.bounded_indices:
            p_clamped = pred[:, :, cidx].clamp(1e-7, 1 - 1e-7)
            tgt = bf[:, :, cidx]
            bce = -(tgt * torch.log(p_clamped) + (1 - tgt) * torch.log(1 - p_clamped))
            m = bfm[:, :, cidx]
            n_obs_m = m.sum()
            if n_obs_m > 0:
                loss = loss + (bce * m).sum() / n_obs_m

        opt_s2s.zero_grad()
        loss.backward()
        opt_s2s.step()
        epoch_loss += loss.item()
        n_batches += 1

    if (epoch + 1) % 50 == 0:
        print(f"  Epoch [{epoch + 1}/200] Loss: {epoch_loss / n_batches:.4f}")
```

```{python}
seq2seq.eval()
s2s_all_predicted = []

with torch.no_grad():
    for idx in val_indices_list:
        xi, mi, _, bi = dataset[idx]
        xi_obs = xi[:landmark_t].unsqueeze(0)
        mi_obs = mi[:landmark_t].unsqueeze(0)

        pred_future = seq2seq(xi_obs, mi_obs, bi.unsqueeze(0),
                              future_target=None, future_len=future_len)

        full_pred = torch.cat([xi[:landmark_t], pred_future.squeeze(0)], dim=0)
        s2s_all_predicted.append(
            dataset.inverse_transform(full_pred.unsqueeze(0)).detach())

s2s_all_predicted = torch.cat(s2s_all_predicted, dim=0).numpy()
```

## 9. Model comparison

We compare all three models — **VAE**, **LMM**, and **Seq2Seq LSTM** — on the
same validation set and future time window ($t = 25 \dots 49$).

```{python}
#| label: tbl-comparison
#| tbl-cap: "Landmark prediction accuracy (future portion only) for the three models."

def compute_metrics(actual, predicted):
    metrics = []
    for col in range(actual.shape[-1]):
        a = actual[:, :, col].ravel()
        p = predicted[:, :, col].ravel()
        mae  = np.mean(np.abs(a - p))
        rmse = np.sqrt(np.mean((a - p) ** 2))
        corr = np.corrcoef(a, p)[0, 1] if np.std(a) > 0 else float('nan')
        metrics.append((mae, rmse, corr))
    return metrics

lmm_future = lmm_predictions[:, landmark_t:, :]
s2s_future = s2s_all_predicted[:, landmark_t:, :]

vae_m = compute_metrics(future_actual, future_pred)
lmm_m = compute_metrics(future_actual, lmm_future)
s2s_m = compute_metrics(future_actual, s2s_future)

header = (f"{'Variable':<20s}  {'VAE':>8s} {'LMM':>8s} {'RNN':>8s}"
          f"  |  {'VAE':>8s} {'LMM':>8s} {'RNN':>8s}"
          f"  |  {'VAE':>8s} {'LMM':>8s} {'RNN':>8s}")
metric_header = (f"{'':20s}  {'--- MAE ---':>26s}"
                 f"  |  {'--- RMSE ---':>26s}"
                 f"  |  {'--- Corr ---':>26s}")
print(metric_header)
print(header)
print("-" * len(header))

for col, v in enumerate(var_config.variables):
    vm, lm, sm = vae_m[col], lmm_m[col], s2s_m[col]
    print(f"{v.name:<20s}  {vm[0]:8.4f} {lm[0]:8.4f} {sm[0]:8.4f}"
          f"  |  {vm[1]:8.4f} {lm[1]:8.4f} {sm[1]:8.4f}"
          f"  |  {vm[2]:8.4f} {lm[2]:8.4f} {sm[2]:8.4f}")
```

## Environment setup

To reproduce this analysis on another machine:

```bash
# 1. Create virtual environment
python -m venv .venv

# 2. Activate it
#    Windows:  .venv\Scripts\activate
#    Linux/Mac: source .venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Install the package in editable mode
pip install -e .

# 5. Register the Jupyter kernel (for Quarto)
python -m ipykernel install --user --name vaelong --display-name "Python (VAElong)"

# 6. Render this document
quarto render examples/mixed_type_example.qmd
```
